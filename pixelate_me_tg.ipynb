{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olegkhomenko/pixelate-me-tg/blob/master/pixelate_me_tg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVvXwLf2x24d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install gdown > /dev/null\n",
        "!pip3 install git+https://github.com/sedthh/pyxelate.git > /dev/null\n",
        "!pip3 install face_recognition > /dev/null\n",
        "!git clone https://github.com/Charleshhy/Grapy-ML > /dev/null\n",
        "\n",
        "# We need 'GPM-ML_finetune_PASCAL.pth' file from\n",
        "# https://drive.google.com/drive/folders/1eQ9IV4QmcM5dLCuVMSVE3ogVpL6qUQL5\n",
        "#\n",
        "# Let's download it directly using gdown and unique 'data-id'\n",
        "!gdown https://drive.google.com/uc?id=1QPwUY9vWmDMnuey2RK4Ief2u4CHqyRjZ > /dev/null\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, f'{os.getcwd()}/Grapy-ML/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPZzQogBvzJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import Optional, Union\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import face_recognition\n",
        "from networks import grapy_net\n",
        "from pyxelate import Pyxelate\n",
        "from utils.util import decode_seg_map_sequence\n",
        "\n",
        "\n",
        "def box_size(box: tuple):\n",
        "    return (box[2] - box[0]) * (box[1] - box[3])\n",
        "\n",
        "\n",
        "def largest_face(face_locations: list):\n",
        "    idx = np.argmax([box_size(box) for box in face_locations])\n",
        "    return face_locations[idx]\n",
        "\n",
        "\n",
        "def get_cropped_image(image: np.ndarray, face_padding=0.6):\n",
        "    face_locations = face_recognition.face_locations(image)\n",
        "\n",
        "    if not len(face_locations):\n",
        "        return None\n",
        "\n",
        "    face_coord = largest_face(face_locations)\n",
        "\n",
        "    h, w, ch = image.shape\n",
        "    box_h = face_coord[2] - face_coord[0]\n",
        "    box_w = face_coord[1] - face_coord[3]\n",
        "\n",
        "    left = max(0, int(face_coord[3] - box_w * face_padding))\n",
        "    right = min(w, int(face_coord[1] + box_w * face_padding))\n",
        "    top = min(h, int(face_coord[2] + box_h * face_padding))\n",
        "    bot = max(0, int(face_coord[0] - box_h * face_padding))\n",
        "\n",
        "    return image[bot:top, left:right]\n",
        "\n",
        "\n",
        "def get_segm_net(weights_path='/content/GPM-ML_finetune_PASCAL.pth'):\n",
        "    net = grapy_net.GrapyMutualLearning(os=16, hidden_layers=256)\n",
        "    net.load_state_dict(torch.load(weights_path))\n",
        "\n",
        "    c1, c2, p1, p2, a1, a2 = (\n",
        "        [[0], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]],\n",
        "        [[0], [1, 2, 4, 13], [5, 6, 7, 10, 11, 12], [3, 14, 15], [8, 9, 16, 17, 18, 19]],\n",
        "        [[0], [1, 2, 3, 4, 5, 6]],\n",
        "        [[0], [1], [2], [3, 4], [5, 6]],\n",
        "        [[0], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]],\n",
        "        [[0], [1, 2, 3, 11], [4, 5, 7, 8, 16, 17], [14, 15], [6, 9, 10, 12, 13]]\n",
        "    )\n",
        "\n",
        "    net.set_category_list(c1, c2, p1, p2, a1, a2)\n",
        "    net.eval()\n",
        "    net.cuda()\n",
        "    return net\n",
        "\n",
        "\n",
        "def pixelate(image: Union[str, np.ndarray],\n",
        "             colors=10, factor=8, dither=False, quantize_by_factor=4,\n",
        "             segmentation_network=None) -> Optional[dict]:\n",
        "    assert isinstance(image, (str, np.ndarray))\n",
        "\n",
        "    if isinstance(image, str):\n",
        "        image = face_recognition.load_image_file(image)\n",
        "\n",
        "    cropped_image = get_cropped_image(image)\n",
        "    if cropped_image is None:\n",
        "        return None\n",
        "\n",
        "    img = cropped_image\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    height, width, _ = img.shape\n",
        "\n",
        "    p = Pyxelate(height // factor, width // factor, colors, dither)\n",
        "    img_small = p.convert(((img // quantize_by_factor) * quantize_by_factor).astype('uint8'))\n",
        "\n",
        "    result['img_small'] = img_small\n",
        "    result['cropped_image'] = cropped_image\n",
        "\n",
        "    if segmentation_network:\n",
        "        segm_net = segmentation_network\n",
        "\n",
        "        t = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((.5, ), (.5, )),\n",
        "                                lambda x: x.unsqueeze(0).cuda(),\n",
        "                                ])\n",
        "\n",
        "        # Getting segmentation mask\n",
        "        with torch.no_grad():\n",
        "            outputs, *_ = segm_net((t(img), 1), training=False)\n",
        "\n",
        "        # Decode segmentation mask\n",
        "        grid_image = make_grid(\n",
        "            decode_seg_map_sequence(torch.max(outputs[:3], 1)[1].detach().cpu().numpy()), 3,\n",
        "            normalize=False,\n",
        "            range=(0, 255))\n",
        "\n",
        "        # Mask binarization\n",
        "        mask_tens = (grid_image.sum(axis=0, keepdim=True) > 0).unsqueeze(0).float()\n",
        "        mask = mask_tens.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
        "\n",
        "        # Finding edges\n",
        "        conv_filter = torch.ones(1, 1, 3, 3)\n",
        "        mask_tens = F.interpolate(mask_tens, (height // factor, width // factor))\n",
        "        contours = F.conv2d(mask_tens, conv_filter, padding=1)\n",
        "        contours = ((contours[0] > 1) & (contours[0] < 6)).float()\n",
        "        contours = contours.permute(1, 2, 0).numpy()\n",
        "\n",
        "        masked_image = img * mask.astype('uint8') + ((mask.repeat(3, axis=2) - 1) * -254).astype('uint8')\n",
        "\n",
        "        img = masked_image\n",
        "\n",
        "        img_segm_small = p.convert((((img // quantize_by_factor)) * quantize_by_factor + (0.75 * quantize_by_factor)).astype('uint8'))\n",
        "        result['img_segm_small'] = img_segm_small\n",
        "\n",
        "        img_small_w_contour = (img_small - (contours * 255)).clip(0, 255).astype('uint8')\n",
        "        result['img_small_w_contour'] = img_small_w_contour\n",
        "\n",
        "        img_segm_small_w_contour = (img_segm_small - (contours * 255)).clip(0, 255).astype('uint8')\n",
        "        result['img_segm_small_w_contour'] = img_segm_small_w_contour\n",
        "\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-YWkb_Akt0V",
        "colab_type": "text"
      },
      "source": [
        "# Telegram BOT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW7AWnvSk6sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install requests > /dev/null\n",
        "!pip3 install pyTelegramBotAPI > /dev/null\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "from io import BytesIO\n",
        "\n",
        "import numpy as np\n",
        "import requests\n",
        "from PIL import Image\n",
        "from skimage.transform import rescale, resize\n",
        "\n",
        "import telebot\n",
        "\n",
        "# SET YOU TELEGRAM TOKEN FROM @BotFather BELOW\n",
        "TOKEN = None\n",
        "assert TOKEN is not None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCNJThcrI91y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bot = telebot.TeleBot(TOKEN)\n",
        "telebot.logger.setLevel(logging.DEBUG)\n",
        "segm_net = get_segm_net()\n",
        "\n",
        "@bot.message_handler(commands=['hi'])\n",
        "def send_welcome(message):\n",
        "    bot.reply_to(message, 'Hi! You can send me a photo')\n",
        "\n",
        "\n",
        "@bot.message_handler(func=lambda message: True)\n",
        "def echo_message(message):\n",
        "    bot.reply_to(message, message.text)\n",
        "\n",
        "\n",
        "@bot.message_handler(content_types= [\"photo\"])\n",
        "def pixelate_handler(message):\n",
        "    global img\n",
        "    bot.send_message(message.chat.id, \"Got your photo. Start working..\")\n",
        "    # Getting photo\n",
        "    file_info = bot.get_file(message.photo[-1].file_id)\n",
        "    r = requests.get('https://api.telegram.org/file/bot{0}/{1}'.format(TOKEN, file_info.file_path))\n",
        "    img = np.array(Image.open(BytesIO(r.content)))\n",
        "    # Pixelating\n",
        "    res = pixelate(img, segmentation_network=segm_net)\n",
        "    if res is not None:\n",
        "        res = res['img_segm_small_w_contour']\n",
        "        # Resizing to ~512\n",
        "        res_rescaled = rescale(res, (int(512 / res.shape[0]), int(512 / res.shape[0]), 1), anti_aliasing=False, order=0)\n",
        "        # Sending back\n",
        "        buf = BytesIO()\n",
        "        plt.imsave(buf, res_rescaled, format='jpg')\n",
        "        bot.send_photo(message.chat.id, buf.getvalue())\n",
        "    else:\n",
        "        bot.send_message(message.chat.id, 'No faces detected. Please look at camera')\n",
        "\n",
        "bot.polling()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "pixelate-me.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "mount_file_id": "115RCHZd_wl_89GbSmX3gtbPoWR7hyk8_",
      "authorship_tag": "ABX9TyOmvBCOQ3MTxdaL0n7gkJ2w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}